{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43aa2cee",
   "metadata": {},
   "source": [
    "# Workshop: DOCX Scraping in Python  \n",
    "### Case Study: KDHE Consumer Confidence Reports\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this workshop, we will build a pipeline to extract structured data from Kansas Department of Health and Environment (KDHE) Consumer Confidence Report (CCR) documents.\n",
    "\n",
    "Public health data is often published as Word/PDF files rather than clean machine-readable tables. Scraping lets us convert these semi-structured documents into analyzable datasets.\n",
    "\n",
    "## When is scraping useful?\n",
    "\n",
    "Use scraping when:\n",
    "- data is publicly available but not downloadable as a single table,\n",
    "- information is spread across many files/pages,\n",
    "- repeated document layouts contain fields you can systematically parse.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be339368",
   "metadata": {},
   "source": [
    "## Workshop Plan\n",
    "\n",
    "This workshop focuses on building a document-scraping workflow for KDHE Consumer Confidence Report (CCR) `.docx` files.\n",
    "\n",
    "### Steps\n",
    "\n",
    "We will:\n",
    "\n",
    "1. Inspect the CCR layout and identify where key fields appear (paragraphs vs tables).\n",
    "2. Review the Python tools used for document parsing and cleaning.\n",
    "3. Build a scraper that extracts relevant fields from each CCR.\n",
    "4. Parse and standardize extracted values into a pandas DataFrame.\n",
    "5. Export a tidy CSV for later analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a528c3",
   "metadata": {},
   "source": [
    "## Core Python Libraries\n",
    "\n",
    "- **os**: file paths, folder traversal, and file management  \n",
    "- **re**: regular expressions for parsing IDs, dates, units, and text patterns  \n",
    "- **python-docx**: read Word (`.docx`) structure (paragraphs, runs, tables, rows, cells)  \n",
    "- **pandas**: tabular wrangling, validation, and CSV export  \n",
    "- **numpy**: helper operations for missing values and numeric transformations  \n",
    "\n",
    "## Environment\n",
    "\n",
    "We will work step-by-step in a Jupyter Notebook, so each stage is:\n",
    "\n",
    "- explained in markdown,\n",
    "- implemented in code cells,\n",
    "- and validated with intermediate outputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "83ce84d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for colab running the docx package needs to be installed. uncomment and run\n",
    "# pip install python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "2e75c10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "0a1712c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first file: \\\\resfs.home.ku.edu\\groups_hipaa\\PSYC\\kdsc_ClassData\\KDSC-CDL-Project2\\Data\\Full Set of CCR Doc Files\\ccrs2025\\kdhe_A_E\\ABBYVILLE-CITY-OF-KS2015512-DOCX.docx\n"
     ]
    }
   ],
   "source": [
    "# Path to where documents have been saved\n",
    "basedir = r\"\\\\resfs.home.ku.edu\\groups_hipaa\\PSYC\\kdsc_ClassData\\KDSC-CDL-Project2\\Data\\Full Set of CCR Doc Files\" \n",
    "subdir = r\"ccrs2025\" #\"ccrs2024docx\"\n",
    "outdir = r\"\\\\resfs.home.ku.edu\\groups_hipaa\\PSYC\\kdsc_ClassData\\KDSC-CDL-Project2\\Output\\CCR_csvs\"\n",
    "root = os.path.join(basedir, subdir)\n",
    "\n",
    "\n",
    "docx_files = []\n",
    "for dirpath, dirnames, filenames in os.walk(root):\n",
    "    for file in filenames:\n",
    "        # Return only docx files. Ignore temporary docx files\n",
    "        if file.lower().endswith(\".docx\") and not file.startswith(\"~$\"):\n",
    "            full_file = os.path.join(dirpath, file)\n",
    "            docx_files.append(full_file)\n",
    "\n",
    "# print(docx_files)\n",
    "print('first file:', docx_files[0])\n",
    "doc_path =  docx_files[0]\n",
    "doc = Document(doc_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed4f8ea",
   "metadata": {},
   "source": [
    "## `python-docx` overview\n",
    "\n",
    "`python-docx` lets us open and read Word documents as structured Python objects.\n",
    "\n",
    "For this document-scraping workflow, we are **extracting data only** and building a new DataFrame.  \n",
    "We do **not** modify source files unless we explicitly call `doc.save(...)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d113c11",
   "metadata": {},
   "source": [
    "### Accessing text in paragraphs\n",
    "\n",
    "After loading a file (for example, `doc = Document(path)`), paragraph text is available in:\n",
    "\n",
    "- `doc.paragraphs` → a list of paragraph objects\n",
    "- `doc.paragraphs[i].text` → the text content of a specific paragraph\n",
    "\n",
    "\n",
    "We will also be using regular expressions for locating the text within the paragraphs.\n",
    "More info on regex can be found at https://docs.python.org/3/library/re.html\n",
    "\n",
    "This is useful when fields that we want to scrape like **PWS Name** and **PWS ID** appear in normal text or headings instead of tables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedd12e6",
   "metadata": {},
   "source": [
    "In the screenshot we see that paragraph objects are seperate elements whenever a page break is used. Note that a textless paragraph still counts as the index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d80b85",
   "metadata": {},
   "source": [
    "![Paragraph Image](https://raw.githubusercontent.com/jbodenheimer/KS_BoilWater_Curriculum/main/doc_paragraph_labeled.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "63dd2c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw paragraph text idx0:\n",
      "CONSUMER CONFIDENCE REPORT CERTIFICATE OF DELIVERY\n",
      "Raw paragraph text idx3:\n",
      "PWS NAME:\tCITY OF ABBYVILLE\t\t\tPWS ID: KS2015512\n"
     ]
    }
   ],
   "source": [
    "# Accessing paragraph text example\n",
    "# Can have small section here for students to answer coding Qs\n",
    "# How many total paragraphs are in this document? What is the index for paragraph x\n",
    "doc_path =  docx_files[0]\n",
    "doc = Document(doc_path)\n",
    "\n",
    "# 1. Selects one paragraph from the paragraph list.  \n",
    "paragraphs = doc.paragraphs\n",
    "p2 = paragraphs[0]\n",
    "# 2. Reads its raw `.text` content.  \n",
    "pws_text = p2.text\n",
    "\n",
    "print(\"Raw paragraph text idx0:\")\n",
    "print(pws_text.strip())\n",
    "\n",
    "# 1. Selects one paragraph from the paragraph list.  \n",
    "paragraphs = doc.paragraphs\n",
    "p2 = paragraphs[3]\n",
    "# 2. Reads its raw `.text` content.  \n",
    "pws_text = p2.text\n",
    "\n",
    "print(\"Raw paragraph text idx3:\")\n",
    "print(pws_text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "b384e118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw paragraph text idx3:\n",
      "PWS NAME:\tCITY OF ABBYVILLE\t\t\tPWS ID: KS2015512\n",
      "Raw paragraph text:\n",
      "PWS NAME:\tCITY OF ABBYVILLE\t\t\tPWS ID: KS2015512\n",
      "\n",
      "Extracted values:\n",
      "PWS Name: CITY OF ABBYVILLE\n",
      "PWS ID: KS2015512\n"
     ]
    }
   ],
   "source": [
    "# Accessing paragraph text example cont.\n",
    "\n",
    "# 1. Selects one paragraph from the paragraph list.  \n",
    "paragraphs = doc.paragraphs\n",
    "p2 = paragraphs[3]\n",
    "# 2. Reads its raw `.text` content.  \n",
    "pws_text = p2.text\n",
    "\n",
    "print(\"Raw paragraph text idx3:\")\n",
    "print(pws_text.strip())\n",
    "\n",
    "# 3. Uses a regex pattern to extract:\n",
    "#    - group 1: PWS Name  \n",
    "#    - group 2: PWS ID \n",
    "# Regex captures:\n",
    "#   group(1) -> text after \"PWS Name:\" up to \"PWS ID:\"\n",
    "#   group(2) -> alphanumeric/hyphen ID after \"PWS ID:\"\n",
    "pattern = r\"pws\\s*name\\s*:\\s*(.*?)\\s+pws\\s*id\\s*:\\s*([A-Za-z0-9\\-]+)\"\n",
    "\n",
    "regex_search = re.search(pattern, pws_text, flags=re.IGNORECASE)\n",
    "\n",
    "\n",
    "# 4. Prints the original paragraph text and the extracted values.\n",
    "print(\"Raw paragraph text:\")\n",
    "print(pws_text.strip())\n",
    "\n",
    "\n",
    "pws_name = regex_search.group(1).strip()\n",
    "pws_id = regex_search.group(2).strip()\n",
    "\n",
    "print(\"\\nExtracted values:\")\n",
    "print(\"PWS Name:\", pws_name)\n",
    "print(\"PWS ID:\", pws_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427d4346",
   "metadata": {},
   "source": [
    "Above we extracted text from a predefined paragraph (paragraph[3]) but a consideration needs to be made for \"will this work with every file?\". With large amounts of files it would take too long to check the layout of each file visually, instead we can write code to be robust to small discrepencies in document layout."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf49cf9",
   "metadata": {},
   "source": [
    "To solve this we can compile the text from paragraphs for the whole document and conduct our regex search on the full text, this way if the paragraph location differs between files we will still catch it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "fbba3063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of paragraphs: 90\n",
      "First paragraph text: CONSUMER CONFIDENCE REPORT CERTIFICATE OF DELIVERY\n"
     ]
    }
   ],
   "source": [
    "# 1) How many paragraphs?\n",
    "print(\"Number of paragraphs:\", len(doc.paragraphs))\n",
    "\n",
    "# 2) Look at the first paragraph\n",
    "p0 = doc.paragraphs[0]\n",
    "print(\"First paragraph text:\", p0.text)\n",
    "\n",
    "# 3) Build one big text block from all paragraph text\n",
    "all_paragraph_text = \"\"\n",
    "for p in doc.paragraphs:\n",
    "    # print(p.text)                    # optional: show each paragraph\n",
    "    # all_paragraph_text += p.text # appends each paragraph into one line\n",
    "    all_paragraph_text += p.text + \"\\n\" # append each paragraph + newline for readability\n",
    "\n",
    "# Uncomment the following to display all text scraped from the page\n",
    "# print(all_paragraph_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "5462f2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw paragraph text:\n",
      "PWS NAME:\tCITY OF ABBYVILLE\t\t\tPWS ID: KS2015512\n",
      "\n",
      "Extracted values:\n",
      "PWS Name: CITY OF ABBYVILLE\n",
      "PWS ID: KS2015512\n"
     ]
    }
   ],
   "source": [
    "pattern = r\"pws\\s*name\\s*:\\s*(.*?)\\s+pws\\s*id\\s*:\\s*([A-Za-z0-9\\-]+)\"\n",
    "\n",
    "regex_search = re.search(pattern, paragraphs_text, flags=re.IGNORECASE)\n",
    "\n",
    "\n",
    "# 4. Prints the original paragraph text and the extracted values.\n",
    "print(\"Raw paragraph text:\")\n",
    "print(pws_text.strip())\n",
    "\n",
    "\n",
    "pws_name = regex_search.group(1).strip()\n",
    "pws_id = regex_search.group(2).strip()\n",
    "\n",
    "print(\"\\nExtracted values:\")\n",
    "print(\"PWS Name:\", pws_name)\n",
    "print(\"PWS ID:\", pws_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd0a861",
   "metadata": {},
   "source": [
    "### Accessing text within tables\n",
    "\n",
    "In `python-docx`, tables are stored separately from paragraphs:\n",
    "\n",
    "- `doc.tables` → list of table objects  \n",
    "- `tables[i].rows` → row objects for table `i`  \n",
    "- `tables[i].rows[r].cells[c]` or `tables[i].cell(r, c)` → specific cell  \n",
    "- `.text` → text content of a cell\n",
    "\n",
    "This is useful when data are presented in displayed in typical row/column fashion.\n",
    "\n",
    "> Note: A table that visually continues onto the next page in Word is often still part of the same table object in `python-docx`, even if repeated headers make it look like a new table.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9db5a7c",
   "metadata": {},
   "source": [
    "![Table Image](https://raw.githubusercontent.com/jbodenheimer/KS_BoilWater_Curriculum/main/doc_table_labeled.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "9c5e011b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total of  5 tables found in the document\n",
      "\n",
      "First cell (cell method):\n",
      "Regulated Contaminants\n",
      "\n",
      "Row count in first table: 6\n",
      "Column count in first row: 8\n",
      "\n",
      "First cell text:\n",
      "Regulated Contaminants\n"
     ]
    }
   ],
   "source": [
    "# Accessing table data example\n",
    "# 1. Loads all tables from the document.\n",
    "doc_path =  docx_files[0]\n",
    "doc = Document(doc_path)\n",
    "tables = doc.tables\n",
    "\n",
    "print(\"\\nTotal of \", len(tables), \"tables found in the document\")\n",
    "# ---need to add pic of the tables and how to iterate over document to get table to use\n",
    "\n",
    "# 2. Access same cell in two equivalent ways\n",
    "print(\"\\nFirst cell (cell method):\")\n",
    "print(tables[0].cell(0, 0).text)\n",
    "\n",
    "# Can also index by calling rows and cells\n",
    "# print(\"\\nFirst cell (rows/cells indexing):\")\n",
    "# print(tables[0].rows[0].cells[0].text)\n",
    "\n",
    "# 3. Table dimensions\n",
    "print(\"\\nRow count in first table:\", len(tables[0].rows))\n",
    "print(\"Column count in first row:\", len(tables[0].rows[0].cells))\n",
    "\n",
    "# 4. Cleaned text\n",
    "print(\"\\nFirst cell text:\")\n",
    "print(tables[0].cell(0, 0).text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7871d95b",
   "metadata": {},
   "source": [
    "Like paragraph extraction, table order in a `.docx` file determines index positions.  \n",
    "If you hard-code `tables[0]`, your script can break if document structure changes between files.\n",
    "\n",
    "A more robust approach is to loop through all tables and look for a known header (for example, `\"regulated contaminants\"` in cell `(0, 0)`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "90b8f381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched table index: 0\n"
     ]
    }
   ],
   "source": [
    "tables = doc.tables\n",
    "rows_out = []  # Collect parsed row data\n",
    "\n",
    "for t, table in enumerate(tables):\n",
    "    # Normalize cell text:\n",
    "    # - strip() removes leading/trailing whitespace\n",
    "    # - casefold() makes matching case-insensitive\n",
    "    header = table.cell(0, 0).text.strip().casefold()\n",
    "\n",
    "    # Looking for the table in the document regulated contaminants data\n",
    "    if header == \"regulated contaminants\":\n",
    "        # Returns table index t with the text 'regulated contaminants' in cell(0,0)\n",
    "        print(\"Matched table index:\", t)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1384fbf",
   "metadata": {},
   "source": [
    "## Outline: contaminant-data extraction\n",
    "\n",
    "These reports include both metadata and water-quality measurements.  \n",
    "Our goal is to extract a consistent set of fields across documents.\n",
    "\n",
    "### Core fields to collect\n",
    "From paragraphs\n",
    "\n",
    "1. **CCR** Report Year\n",
    "2. **CCR** Covering Year\n",
    "3. **PWS Name** (Public Water System name)  \n",
    "4. **PWS ID** \n",
    "\n",
    "From Table\n",
    "\n",
    "5. **Testing results**, including:\n",
    "   - Regulated contaminants\n",
    "   - Lead and copper\n",
    "   - Chlorine/chloramines (disinfection residual / MRDL-related section)\n",
    "   - Secondary contaminants (non-health-based standards)\n",
    "   <!-- - Compliance period (when reported values apply) -->\n",
    "\n",
    "### Parsing notes\n",
    "\n",
    "- Some values appear in paragraph text, others in tables, so we will need to use both to extract the desired data.\n",
    "- Section titles may vary slightly across reports, so pattern matching and defensive parsing of text are important.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055c4f21",
   "metadata": {},
   "source": [
    "## Step 1: Extract PWS metadata from one document (paragraph text)\n",
    "\n",
    "Before processing many files, we first test extraction on a smaller batch.\n",
    "\n",
    "In this step we collect the information needed from paragraphs of the document:\n",
    "\n",
    "1. Open one `.docx` file.\n",
    "2. Access `doc.paragraphs`.\n",
    "3. Select the paragraph that contains `PWS Name` and `PWS ID`.\n",
    "4. Use a regex pattern to extract:\n",
    "   - `pws name`\n",
    "   - `pws id`\n",
    "   - `Covering year`\n",
    "   - `Calendar year`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "be844f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracted:\n",
      "pws name: CITY OF ABBYVILLE\n",
      "pws id  : KS2015512\n",
      "Report year: 2025\n",
      "Covering year: 2024\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Paragraph extraction from ONE document (no file loop)\n",
    "\n",
    "doc_path = docx_files[0]  # pick one file for demonstration\n",
    "doc = Document(doc_path)\n",
    "\n",
    "paragraphs = doc.paragraphs\n",
    "\n",
    "################# Create Variable with all paragraph text ####################\n",
    "all_paragraph_text = \"\"\n",
    "for p in doc.paragraphs:\n",
    "    all_paragraph_text += p.text + \"\\n\" # append each paragraph + newline\n",
    "\n",
    "\n",
    "################# Search for PWS ####################\n",
    "# This the pws name and pws ID appear in the same line so we can set up a single regex pattern to find both\n",
    "# We could also accomplish this by searching for pws name and pws ID seperately\n",
    "pws_pattern = r\"pws\\s*name\\s*:\\s*(.*?)\\s+pws\\s*id\\s*:\\s*([A-Za-z0-9\\-]+)\"\n",
    "match = re.search(pws_pattern, all_paragraph_text, flags=re.IGNORECASE)\n",
    "\n",
    "\n",
    "if match:\n",
    "    pws_name = match.group(1).strip()\n",
    "    pws_id = match.group(2).strip()\n",
    "    print(\"\\nExtracted:\")\n",
    "    print(\"pws name:\", pws_name)\n",
    "    print(\"pws id  :\", pws_id)\n",
    "else:\n",
    "    pws_name, pws_id = None, None\n",
    "    print(\"\\nv not found in selected paragraph.\")\n",
    "\n",
    "################# Search for the Reporting Year ####################\n",
    "CCR_ReportYear_pattern =  r\"Consumer Confidence Report\\s*[–-]\\s*(\\d{4}).*?\"\n",
    "CCR_ReportYear_match = re.search(CCR_ReportYear_pattern, all_paragraph_text, flags=re.IGNORECASE)\n",
    "\n",
    "if CCR_ReportYear_match:\n",
    "    report_year = int(CCR_ReportYear_match.group(1))\n",
    "    print(\"Report year:\", report_year)\n",
    "else:\n",
    "    report_year = None\n",
    "    print(\"\\nCCR_ReportYear_pattern not found in selected paragraph.\")\n",
    "\n",
    "################# Search for Calendar Year ####################\n",
    "CCR_CalYear_pattern = r\"Covering Calendar Year\\s*[–-]\\s*(\\d{4})\"\n",
    "CCR_CalYear_match = re.search(CCR_CalYear_pattern, all_paragraph_text, flags=re.IGNORECASE)\n",
    "if CCR_CalYear_match:\n",
    "    covering_year = int(CCR_CalYear_match.group(1))\n",
    "    print(\"Covering year:\", covering_year)\n",
    "else:\n",
    "    covering_year = None\n",
    "    print(\"\\nCCR_CalYear_pattern not found in selected paragraph.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392c0373",
   "metadata": {},
   "source": [
    "## Step 2: Extract regulated contaminant rows from one document (table text)\n",
    "\n",
    "Now we extract table rows from the same single report.\n",
    "\n",
    "In this step we:\n",
    "\n",
    "1. Access `doc.tables`.\n",
    "2. Find the table whose top-left cell is `\"regulated contaminants\"`.\n",
    "3. Read header cells from row 0.\n",
    "4. Read each data row into a dictionary.\n",
    "5. Convert extracted rows into a DataFrame.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "3e04abd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['regulated contaminants', 'collection date', 'highest value', 'range\\n(low/high)', 'unit', '', 'mclg', 'typical source']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>covering year</th>\n",
       "      <th>report_year</th>\n",
       "      <th>pws name</th>\n",
       "      <th>pws id</th>\n",
       "      <th>regulated contaminants</th>\n",
       "      <th>collection date</th>\n",
       "      <th>highest value</th>\n",
       "      <th>range\\n(low/high)</th>\n",
       "      <th>unit</th>\n",
       "      <th>mcl</th>\n",
       "      <th>mclg</th>\n",
       "      <th>typical source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>ARSENIC</td>\n",
       "      <td>4/15/2024</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>ppb</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>Erosion of natural deposits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>BARIUM</td>\n",
       "      <td>4/15/2024</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.46</td>\n",
       "      <td>ppm</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>Discharge from metal refineries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>ETHYLBENZENE</td>\n",
       "      <td>6/10/2024</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0 - 1.2</td>\n",
       "      <td>ppb</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>700</td>\n",
       "      <td>Discharge from petroleum refineries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NITRATE</td>\n",
       "      <td>4/15/2024</td>\n",
       "      <td>6</td>\n",
       "      <td>5.8 - 6</td>\n",
       "      <td>ppm</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>Runoff from fertilizer use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>XYLENES, TOTAL</td>\n",
       "      <td>6/10/2024</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.0051 - 0.013</td>\n",
       "      <td>ppm</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>Discharge from petroleum factories; Discharge ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  covering year report_year pws name pws id regulated contaminants  \\\n",
       "0          <NA>        <NA>     <NA>   <NA>                ARSENIC   \n",
       "1          <NA>        <NA>     <NA>   <NA>                 BARIUM   \n",
       "2          <NA>        <NA>     <NA>   <NA>           ETHYLBENZENE   \n",
       "3          <NA>        <NA>     <NA>   <NA>                NITRATE   \n",
       "4          <NA>        <NA>     <NA>   <NA>         XYLENES, TOTAL   \n",
       "\n",
       "  collection date highest value range\\n(low/high) unit   mcl mclg  \\\n",
       "0       4/15/2024           1.5               1.5  ppb  <NA>    0   \n",
       "1       4/15/2024          0.46              0.46  ppm  <NA>    2   \n",
       "2       6/10/2024           1.2           0 - 1.2  ppb  <NA>  700   \n",
       "3       4/15/2024             6           5.8 - 6  ppm  <NA>   10   \n",
       "4       6/10/2024         0.013    0.0051 - 0.013  ppm  <NA>   10   \n",
       "\n",
       "                                      typical source  \n",
       "0                        Erosion of natural deposits  \n",
       "1                    Discharge from metal refineries  \n",
       "2                Discharge from petroleum refineries  \n",
       "3                         Runoff from fertilizer use  \n",
       "4  Discharge from petroleum factories; Discharge ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: have blank header(s): ['regulated contaminants', 'collection date', 'highest value', 'range\\n(low/high)', 'unit', '', 'mclg', 'typical source']\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Table extraction from ONE document\n",
    "\n",
    "expected_headers = [\n",
    "    'covering year', 'report_year','pws name', 'pws id', 'regulated contaminants', 'collection date',\n",
    "    'highest value', 'range\\n(low/high)', 'unit', 'mcl', 'mclg', 'typical source'\n",
    "]\n",
    "\n",
    "tables = doc.tables\n",
    "rows_out = []\n",
    "target_table = None\n",
    "\n",
    "# Find the regulated contaminants table\n",
    "for table in tables:\n",
    "\n",
    "    first_cell = table.cell(0, 0).text.replace('\\xa0', ' ').strip().casefold()\n",
    "    if first_cell == \"regulated contaminants\":\n",
    "        target_table = table\n",
    "        break\n",
    "\n",
    "if target_table is None:\n",
    "    print(\"No 'regulated contaminants' table found.\")\n",
    "    table_df = pd.DataFrame(columns=expected_headers)\n",
    "else:\n",
    "    # Clean headers\n",
    "    headers = [\n",
    "        cell.text.replace('\\xa0', ' ').strip().casefold()\n",
    "        for cell in target_table.rows[0].cells\n",
    "    ]\n",
    "\n",
    "    # Extract data rows (skip header row at index 0)\n",
    "    for r in range(1, len(target_table.rows)):\n",
    "        row_data = {\n",
    "            headers[c]: target_table.cell(r, c).text.replace('\\xa0', ' ').strip()\n",
    "            for c in range(len(headers))\n",
    "        }\n",
    "        rows_out.append(row_data)\n",
    "\n",
    "    table_df = pd.DataFrame(rows_out)\n",
    "\n",
    "    # Ensure expected columns exist and order them\n",
    "    for col in expected_headers:\n",
    "        if col not in table_df.columns:\n",
    "            table_df[col] = pd.NA\n",
    "    table_df = table_df[expected_headers]\n",
    "print(headers)\n",
    "# print(row_data)\n",
    "display(table_df)\n",
    "\n",
    "if \"\" in headers:\n",
    "    print(\"Warning: have blank header(s):\", headers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0838824",
   "metadata": {},
   "source": [
    "#### Fixing a missing `MCL` header during `.docx` table extraction\n",
    "\n",
    "Sometimes the `MCL` column ends up empty when extracting the **Regulated Contaminants** table with `python-docx`. This can happen because the header row contains merged cells, and `python-docx` may return an empty string (`\"\"`) for a header cell even though the text is visible in Word.\n",
    "\n",
    "In our case, the header list looked like:\n",
    "\n",
    "```python\n",
    "['regulated contaminants', 'collection date', 'highest value',\n",
    " 'range\\n(low/high)', 'unit', '', 'mclg', 'typical source']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "497d19bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['regulated contaminants', 'collection date', 'highest value', 'range\\n(low/high)', 'unit', '', 'mclg', 'typical source']\n",
      "['regulated contaminants', 'collection date', 'highest value', 'range\\n(low/high)', 'unit', 'mcl', 'mclg', 'typical source']\n"
     ]
    }
   ],
   "source": [
    "# If there's an empty header between Unit and MCLG, it's MCL\n",
    "print(headers)\n",
    "for i in range(1, len(headers)-1):\n",
    "    if headers[i] == \"\" and headers[i-1] == \"unit\" and headers[i+1] == \"mclg\":\n",
    "        headers[i] = \"mcl\"\n",
    "print(headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694706e5",
   "metadata": {},
   "source": [
    "Putting the header patch directly into the extraction step ensures `MCL` values land in the correct DataFrame column (instead of being stored under a blank column name and later dropped during reordering).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "0a0c90e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['regulated contaminants', 'collection date', 'highest value', 'range\\n(low/high)', 'unit', 'mcl', 'mclg', 'typical source']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>covering year</th>\n",
       "      <th>report_year</th>\n",
       "      <th>pws name</th>\n",
       "      <th>pws id</th>\n",
       "      <th>regulated contaminants</th>\n",
       "      <th>collection date</th>\n",
       "      <th>highest value</th>\n",
       "      <th>range\\n(low/high)</th>\n",
       "      <th>unit</th>\n",
       "      <th>mcl</th>\n",
       "      <th>mclg</th>\n",
       "      <th>typical source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>BARIUM</td>\n",
       "      <td>1/24/2024</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>ppm</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Discharge from metal refineries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>CHROMIUM</td>\n",
       "      <td>1/24/2024</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>ppb</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>Discharge from steel and pulp mills</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>FLUORIDE</td>\n",
       "      <td>1/24/2024</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.49</td>\n",
       "      <td>ppm</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Natural deposits; Water additive which promote...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NITRATE</td>\n",
       "      <td>1/24/2024</td>\n",
       "      <td>8.4</td>\n",
       "      <td>8 - 8.4</td>\n",
       "      <td>ppm</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>Runoff from fertilizer use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>SELENIUM</td>\n",
       "      <td>1/24/2024</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>ppb</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>Erosion of natural deposits</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  covering year report_year pws name pws id regulated contaminants  \\\n",
       "0          <NA>        <NA>     <NA>   <NA>                 BARIUM   \n",
       "1          <NA>        <NA>     <NA>   <NA>               CHROMIUM   \n",
       "2          <NA>        <NA>     <NA>   <NA>               FLUORIDE   \n",
       "3          <NA>        <NA>     <NA>   <NA>                NITRATE   \n",
       "4          <NA>        <NA>     <NA>   <NA>               SELENIUM   \n",
       "\n",
       "  collection date highest value range\\n(low/high) unit  mcl mclg  \\\n",
       "0       1/24/2024          0.16              0.16  ppm    2    2   \n",
       "1       1/24/2024           1.4               1.4  ppb  100  100   \n",
       "2       1/24/2024          0.49              0.49  ppm    4    4   \n",
       "3       1/24/2024           8.4           8 - 8.4  ppm   10   10   \n",
       "4       1/24/2024           1.5               1.5  ppb   50   50   \n",
       "\n",
       "                                      typical source  \n",
       "0                    Discharge from metal refineries  \n",
       "1                Discharge from steel and pulp mills  \n",
       "2  Natural deposits; Water additive which promote...  \n",
       "3                         Runoff from fertilizer use  \n",
       "4                        Erosion of natural deposits  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 2: Table extraction from ONE document\n",
    "\n",
    "expected_headers = [\n",
    "    'covering year', 'report_year','pws name', 'pws id', 'regulated contaminants', 'collection date',\n",
    "    'highest value', 'range\\n(low/high)', 'unit', 'mcl', 'mclg', 'typical source'\n",
    "]\n",
    "\n",
    "tables = doc.tables\n",
    "rows_out = []\n",
    "target_table = None\n",
    "\n",
    "# Find the regulated contaminants table\n",
    "for table in tables:\n",
    "\n",
    "    first_cell = table.cell(0, 0).text.replace('\\xa0', ' ').strip().casefold()\n",
    "    if first_cell == \"regulated contaminants\":\n",
    "        target_table = table\n",
    "        break\n",
    "\n",
    "if target_table is None:\n",
    "    print(\"No 'regulated contaminants' table found.\")\n",
    "    table_df = pd.DataFrame(columns=expected_headers)\n",
    "else:\n",
    "    # Clean headers\n",
    "    headers = [\n",
    "        cell.text.replace('\\xa0', ' ').strip().casefold()\n",
    "        for cell in target_table.rows[0].cells\n",
    "    ]\n",
    "\n",
    "    for i in range(1, len(headers) - 1):\n",
    "        if headers[i] == \"\" and headers[i-1] == \"unit\" and headers[i+1] == \"mclg\":\n",
    "            headers[i] = \"mcl\"\n",
    "\n",
    "    # Extract data rows (skip header row at index 0)\n",
    "    for r in range(1, len(target_table.rows)):\n",
    "        row_data = {\n",
    "            headers[c]: target_table.cell(r, c).text.replace('\\xa0', ' ').strip()\n",
    "            for c in range(len(headers))\n",
    "        }\n",
    "        rows_out.append(row_data)\n",
    "\n",
    "    table_df = pd.DataFrame(rows_out)\n",
    "\n",
    "    # Ensure expected columns exist and order them\n",
    "    for col in expected_headers:\n",
    "        if col not in table_df.columns:\n",
    "            table_df[col] = pd.NA\n",
    "    table_df = table_df[expected_headers]\n",
    "print(headers)\n",
    "# print(row_data)\n",
    "display(table_df)\n",
    "\n",
    "if \"\" in headers:\n",
    "    print(\"Warning: have blank header(s):\", headers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b136005",
   "metadata": {},
   "source": [
    "## Step 3: Scale up to multiple files\n",
    "\n",
    "After validating extraction on one report, we can apply the same logic across many documents.\n",
    "\n",
    "This full-loop version:\n",
    "\n",
    "1. Iterates through selected files.\n",
    "2. Extracts `pws name`/`pws id` from paragraphs.\n",
    "3. Finds and parses the `\"regulated contaminants\"` table.\n",
    "4. Appends each file’s rows into one combined DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8453d7bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>covering year</th>\n",
       "      <th>report year</th>\n",
       "      <th>pws name</th>\n",
       "      <th>pws id</th>\n",
       "      <th>regulated contaminants</th>\n",
       "      <th>collection date</th>\n",
       "      <th>highest value</th>\n",
       "      <th>range\\n(low/high)</th>\n",
       "      <th>unit</th>\n",
       "      <th>mcl</th>\n",
       "      <th>mclg</th>\n",
       "      <th>typical source</th>\n",
       "      <th>water system</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024</td>\n",
       "      <td>2025</td>\n",
       "      <td>CITY OF ABBYVILLE</td>\n",
       "      <td>KS2015512</td>\n",
       "      <td>BARIUM</td>\n",
       "      <td>1/24/2024</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>ppm</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Discharge from metal refineries</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024</td>\n",
       "      <td>2025</td>\n",
       "      <td>CITY OF ABBYVILLE</td>\n",
       "      <td>KS2015512</td>\n",
       "      <td>CHROMIUM</td>\n",
       "      <td>1/24/2024</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>ppb</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>Discharge from steel and pulp mills</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024</td>\n",
       "      <td>2025</td>\n",
       "      <td>CITY OF ABBYVILLE</td>\n",
       "      <td>KS2015512</td>\n",
       "      <td>FLUORIDE</td>\n",
       "      <td>1/24/2024</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.49</td>\n",
       "      <td>ppm</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Natural deposits; Water additive which promote...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024</td>\n",
       "      <td>2025</td>\n",
       "      <td>CITY OF ABBYVILLE</td>\n",
       "      <td>KS2015512</td>\n",
       "      <td>NITRATE</td>\n",
       "      <td>1/24/2024</td>\n",
       "      <td>8.4</td>\n",
       "      <td>8 - 8.4</td>\n",
       "      <td>ppm</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>Runoff from fertilizer use</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024</td>\n",
       "      <td>2025</td>\n",
       "      <td>CITY OF ABBYVILLE</td>\n",
       "      <td>KS2015512</td>\n",
       "      <td>SELENIUM</td>\n",
       "      <td>1/24/2024</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>ppb</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>Erosion of natural deposits</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3766</th>\n",
       "      <td>2024</td>\n",
       "      <td>2025</td>\n",
       "      <td>CITY OF ZENDA</td>\n",
       "      <td>KS2009506</td>\n",
       "      <td>ARSENIC</td>\n",
       "      <td>4/15/2024</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>ppb</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>Erosion of natural deposits</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3767</th>\n",
       "      <td>2024</td>\n",
       "      <td>2025</td>\n",
       "      <td>CITY OF ZENDA</td>\n",
       "      <td>KS2009506</td>\n",
       "      <td>BARIUM</td>\n",
       "      <td>4/15/2024</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.46</td>\n",
       "      <td>ppm</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Discharge from metal refineries</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3768</th>\n",
       "      <td>2024</td>\n",
       "      <td>2025</td>\n",
       "      <td>CITY OF ZENDA</td>\n",
       "      <td>KS2009506</td>\n",
       "      <td>ETHYLBENZENE</td>\n",
       "      <td>6/10/2024</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0 - 1.2</td>\n",
       "      <td>ppb</td>\n",
       "      <td>700</td>\n",
       "      <td>700</td>\n",
       "      <td>Discharge from petroleum refineries</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3769</th>\n",
       "      <td>2024</td>\n",
       "      <td>2025</td>\n",
       "      <td>CITY OF ZENDA</td>\n",
       "      <td>KS2009506</td>\n",
       "      <td>NITRATE</td>\n",
       "      <td>4/15/2024</td>\n",
       "      <td>6</td>\n",
       "      <td>5.8 - 6</td>\n",
       "      <td>ppm</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>Runoff from fertilizer use</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3770</th>\n",
       "      <td>2024</td>\n",
       "      <td>2025</td>\n",
       "      <td>CITY OF ZENDA</td>\n",
       "      <td>KS2009506</td>\n",
       "      <td>XYLENES, TOTAL</td>\n",
       "      <td>6/10/2024</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.0051 - 0.013</td>\n",
       "      <td>ppm</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>Discharge from petroleum factories; Discharge ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3771 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     covering year report year           pws name     pws id  \\\n",
       "0             2024        2025  CITY OF ABBYVILLE  KS2015512   \n",
       "1             2024        2025  CITY OF ABBYVILLE  KS2015512   \n",
       "2             2024        2025  CITY OF ABBYVILLE  KS2015512   \n",
       "3             2024        2025  CITY OF ABBYVILLE  KS2015512   \n",
       "4             2024        2025  CITY OF ABBYVILLE  KS2015512   \n",
       "...            ...         ...                ...        ...   \n",
       "3766          2024        2025      CITY OF ZENDA  KS2009506   \n",
       "3767          2024        2025      CITY OF ZENDA  KS2009506   \n",
       "3768          2024        2025      CITY OF ZENDA  KS2009506   \n",
       "3769          2024        2025      CITY OF ZENDA  KS2009506   \n",
       "3770          2024        2025      CITY OF ZENDA  KS2009506   \n",
       "\n",
       "     regulated contaminants collection date highest value range\\n(low/high)  \\\n",
       "0                    BARIUM       1/24/2024          0.16              0.16   \n",
       "1                  CHROMIUM       1/24/2024           1.4               1.4   \n",
       "2                  FLUORIDE       1/24/2024          0.49              0.49   \n",
       "3                   NITRATE       1/24/2024           8.4           8 - 8.4   \n",
       "4                  SELENIUM       1/24/2024           1.5               1.5   \n",
       "...                     ...             ...           ...               ...   \n",
       "3766                ARSENIC       4/15/2024           1.5               1.5   \n",
       "3767                 BARIUM       4/15/2024          0.46              0.46   \n",
       "3768           ETHYLBENZENE       6/10/2024           1.2           0 - 1.2   \n",
       "3769                NITRATE       4/15/2024             6           5.8 - 6   \n",
       "3770         XYLENES, TOTAL       6/10/2024         0.013    0.0051 - 0.013   \n",
       "\n",
       "     unit  mcl mclg                                     typical source  \\\n",
       "0     ppm    2    2                    Discharge from metal refineries   \n",
       "1     ppb  100  100                Discharge from steel and pulp mills   \n",
       "2     ppm    4    4  Natural deposits; Water additive which promote...   \n",
       "3     ppm   10   10                         Runoff from fertilizer use   \n",
       "4     ppb   50   50                        Erosion of natural deposits   \n",
       "...   ...  ...  ...                                                ...   \n",
       "3766  ppb   10    0                        Erosion of natural deposits   \n",
       "3767  ppm    2    2                    Discharge from metal refineries   \n",
       "3768  ppb  700  700                Discharge from petroleum refineries   \n",
       "3769  ppm   10   10                         Runoff from fertilizer use   \n",
       "3770  ppm   10   10  Discharge from petroleum factories; Discharge ...   \n",
       "\n",
       "     water system  \n",
       "0             NaN  \n",
       "1             NaN  \n",
       "2             NaN  \n",
       "3             NaN  \n",
       "4             NaN  \n",
       "...           ...  \n",
       "3766          NaN  \n",
       "3767          NaN  \n",
       "3768          NaN  \n",
       "3769          NaN  \n",
       "3770          NaN  \n",
       "\n",
       "[3771 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Table Extraction for REgulated Contaminants\n",
    "expected_headers = ['covering year', 'report year', 'pws name', 'pws id', 'regulated contaminants', 'collection date', 'highest value', 'range\\n(low/high)','unit','mcl','mclg','typical source']\n",
    "\n",
    "# Setup a dataframe for extracted data\n",
    "df = pd.DataFrame(columns=expected_headers) \n",
    "\n",
    "# Loops through all files and perform extraction on each file\n",
    "for i, file in enumerate(docx_files):\n",
    "\n",
    "    # Index and bring a docx file \n",
    "    doc_path = (docx_files[i])\n",
    "\n",
    "    doc = Document(doc_path)\n",
    "\n",
    "    ###################### Paragraph Extraction #####################\n",
    "    paragraphs = doc.paragraphs\n",
    "    all_paragraph_text = \"\"\n",
    "    for p in doc.paragraphs:\n",
    "        all_paragraph_text += p.text + \"\\n\" # append each paragraph + newline\n",
    "\n",
    "    # Extract pws name and pws ID\n",
    "    pws_pattern = r\"pws\\s*name\\s*:\\s*(.*?)\\s+pws\\s*id\\s*:\\s*([A-Za-z0-9\\-]+)\"\n",
    "    match = re.search(pws_pattern, all_paragraph_text, flags=re.IGNORECASE)\n",
    "\n",
    "    if match:\n",
    "        pws_name = match.group(1).strip()\n",
    "        pws_id = match.group(2).strip()\n",
    "        # print(\"\\nExtracted:\")\n",
    "        # print(\"pws name:\", pws_name)\n",
    "        # print(\"pws id  :\", pws_id)\n",
    "    else:\n",
    "        pws_name, pws_id = None, None\n",
    "        print(\"\\nv not found in selected paragraph.\")\n",
    "\n",
    "    # Extract the Report Year from the file\n",
    "    CCR_ReportYear_pattern =  r\"Consumer Confidence Report\\s*[–-]\\s*(\\d{4}).*?\"\n",
    "    CCR_ReportYear_match = re.search(CCR_ReportYear_pattern, all_paragraph_text, flags=re.IGNORECASE)\n",
    "\n",
    "    if CCR_ReportYear_match:\n",
    "        report_year = int(CCR_ReportYear_match.group(1))\n",
    "        # print(\"Report year:\", report_year)\n",
    "    else:\n",
    "        report_year = None\n",
    "        print(\"\\nCCR_ReportYear_pattern not found in selected paragraph.\")\n",
    "\n",
    "    # Extract the Calendar Year from the file\n",
    "    CCR_CalYear_pattern = r\"Covering Calendar Year\\s*[–-]\\s*(\\d{4})\"\n",
    "    CCR_CalYear_match = re.search(CCR_CalYear_pattern, all_paragraph_text, flags=re.IGNORECASE)\n",
    "    if CCR_CalYear_match:\n",
    "        covering_year = int(CCR_CalYear_match.group(1))\n",
    "        # print(\"Covering year:\", covering_year)\n",
    "    else:\n",
    "        covering_year = None\n",
    "        print(\"\\nCCR_CalYear_pattern not found in selected paragraph.\")\n",
    "\n",
    "    \n",
    "    ###################### Table Extraction #########################\n",
    "    tables = doc.tables\n",
    "    rows_out = [] # setup variable for row data\n",
    "    for t, table in enumerate(tables):       \n",
    "\n",
    "        if tables[t].cell(0,0).text.strip().casefold() == \"regulated contaminants\": #strip removes white space and casefold avoids capitalization issues\n",
    "            txt = table.cell(0, 5).text\n",
    "            raw = table.cell(0, 5).text\n",
    "            clean = raw.replace('\\xa0', ' ').strip()\n",
    "\n",
    "            headers = [cell.text.strip().casefold() for cell in table.rows[0].cells] #get all the headers of the current table\n",
    "\n",
    "            # If there's an empty header between Unit and MCLG, it's MCL\n",
    "            for i in range(1, len(headers)-1):\n",
    "                if headers[i] == \"\" and headers[i-1] == \"unit\" and headers[i+1] == \"mclg\":\n",
    "                    headers[i] = \"mcl\"\n",
    "            if \"\" in headers:\n",
    "                print(\"Warning: have blank header(s):\", headers)\n",
    "            for r in range(1, len(table.rows)):\n",
    "                # Explain \n",
    "                row_data = {headers[c]: table.cell(r, c).text.strip() for c in range(len(headers))}\n",
    "                # print(row_data)\n",
    "                rows_out.append(row_data)\n",
    "\n",
    "    # Create a dataframe of the extracted table data\n",
    "    table_df = pd.DataFrame(rows_out)\n",
    "\n",
    "    # Add the data extracted from paragraphs to our table dataframe\n",
    "    table_df[\"covering year\"] = covering_year\n",
    "    table_df[\"report year\"] = report_year\n",
    "    table_df[\"pws name\"] = pws_name\n",
    "    table_df[\"pws id\"] = pws_id\n",
    "\n",
    "    # Append \n",
    "    df = pd.concat([df, table_df], ignore_index=True)\n",
    "\n",
    "display(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "3cbc3726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Dataframe to the outpur dir as a csv with the directory name we got the files from\n",
    "# df.to_csv(outdir, '/', subdir + \"regulated_contaminants_output.csv\", index=False)\n",
    "out_path = os.path.join(outdir, f\"{subdir}_regulated_contaminants_output.csv\")\n",
    "df.to_csv(out_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4e21c2",
   "metadata": {},
   "source": [
    "## Data Quality & Exploration Questions\n",
    "\n",
    "Data quality and summary questions for the CCR created table.\n",
    "\n",
    "---\n",
    "\n",
    "### Question 1) Coverage and uniqueness\n",
    "- **How many unique water systems are represented in the table?**\n",
    "  - Use: `pws id`\n",
    "  - Suggested method: `.nunique()`\n",
    "\n",
    "---\n",
    "\n",
    "### Question 2) Missing values\n",
    "- **How many rows are missing one or more fields? Which headers have missing data?**\n",
    "  - Suggested method: `.isna()` + row-wise checks\n",
    "\n",
    "---\n",
    "\n",
    "### Question 3) Year consistency checks\n",
    "- **Are `report year` and `covering year` ever inconsistent?**\n",
    "  - Identify rows where the two year fields do not align with expected logic.\n",
    "  - Suggested method: `.value_counts()`\n",
    "\n",
    "---\n",
    "\n",
    "### Question 4) Duplicate observation checks\n",
    "- **Do duplicate observations exist for the same observation?**\n",
    "  - Suggested method: `.duplicated(...)`\n",
    "\n",
    "---\n",
    "\n",
    "### Question 5) Contaminant inventory and reporting breadth\n",
    "- **What contaminants are reported in the dataset?**\n",
    "- **How many cities report each contaminant?**\n",
    "  - Suggested methods:\n",
    "    - `.value_counts()` for frequency\n",
    "    - `.nunique()` for city counts\n",
    "\n",
    "---\n",
    "\n",
    "### Question 6) Extremes for top contaminants\n",
    "- **For the top 3 most reported contaminants:**\n",
    "  - Which city/cities have the **highest** recorded `highest value`?\n",
    "  - Which city/cities have the **lowest** recorded `highest value`?\n",
    "\n",
    "---\n",
    "\n",
    "### Helpful pandas tools\n",
    "- `.nunique()`\n",
    "- `.groupby()`\n",
    "- `.value_counts()`\n",
    "- `.duplicated()`\n",
    "- `.isna()`\n",
    "- `.agg()`\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "webscrape-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
